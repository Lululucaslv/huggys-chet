import OpenAI from 'openai'
import { OpenAIStream, StreamingTextResponse } from 'ai'

export const runtime = 'edge'

export default async function handler(req) {
  console.log('ğŸ”¥ v32 - CHAT ENDPOINT HIT - CLEAN SIMPLIFIED VERSION')
  
  if (req.method !== 'POST') {
    console.log('âŒ Method not allowed:', req.method)
    return new Response(JSON.stringify({ error: 'Method not allowed' }), {
      status: 405,
      headers: { 'Content-Type': 'application/json' }
    })
  }

  try {
    console.log('ğŸ”¥ v32 - Parsing request body...')
    const body = await req.json()
    console.log('ğŸ”¥ v32 - Request body received')
    
    const { tool, userMessage, userId } = body

    if (!tool || !userMessage || !userId) {
      console.log('âŒ Missing required parameters')
      return new Response(JSON.stringify({ error: 'Missing required parameters' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json' }
      })
    }

    if (tool !== 'chatWithTools') {
      console.log('âŒ Invalid tool specified:', tool)
      return new Response(JSON.stringify({ error: 'Invalid tool specified' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json' }
      })
    }

    console.log('ğŸ”¥ v32 - Environment check passed')

    if (!process.env.OPENAI_API_KEY) {
      console.error('âŒ Missing OpenAI API key')
      return new Response(JSON.stringify({ error: 'Server configuration error' }), {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      })
    }

    console.log('ğŸ”¥ v32 - Creating OpenAI client...')
    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    })

    console.log('ğŸ”¥ v32 - Creating conversation messages...')
    const conversationMessages = [
      {
        role: "system",
        content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å¥åº·åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·é¢„çº¦å¿ƒç†å’¨è¯¢å¸ˆã€‚

å½“ç”¨æˆ·è¯¢é—®å’¨è¯¢å¸ˆçš„å¯é¢„çº¦æ—¶é—´æ—¶ï¼Œä½ åº”è¯¥è°ƒç”¨å·¥å…·æ¥æŸ¥è¯¢å®é™…çš„å¯é¢„çº¦æ—¶é—´ã€‚
è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œå¹¶æä¾›æ¸…æ™°ã€æœ‰ç”¨çš„ä¿¡æ¯ã€‚`
      },
      {
        role: "user",
        content: userMessage
      }
    ]

    console.log('ğŸ”¥ v32 - Making streaming OpenAI call...')
    const streamingResponse = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: conversationMessages,
      temperature: 0.3,
      max_tokens: 1500,
      stream: true
    })
    
    console.log('ğŸ”¥ v32 - Creating stream response...')
    const stream = OpenAIStream(streamingResponse)
    return new StreamingTextResponse(stream)

  } catch (error) {
    console.error('âŒ v32 Handler error:', error)
    console.error('âŒ Error message:', error.message)
    return new Response(JSON.stringify({ 
      error: 'Internal server error', 
      details: error.message
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    })
  }
}
